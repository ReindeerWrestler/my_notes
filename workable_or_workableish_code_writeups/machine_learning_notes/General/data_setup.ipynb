{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def split_data_to_x_y(data, input_length, output_length=20, only_window=True, forecast_column_index=4):  # older version\n",
    "#     \"\"\"\n",
    "#     Takes in a the data that has been passed through chunk_data. Reshapes it back into a numpy matrix,\n",
    "#     Then starts to chunk the data again. It will grab an inputted amount of lagged values that are to be used in\n",
    "#     the lstm. Will do the same with the forecasted value. Then return those values so that they are ready to be\n",
    "#     used by the lstm.\n",
    "#\n",
    "#     :param forecast_column_index: index column of the what uni variate value I want to be forecasted\n",
    "#     :param data: my input data, will have passed through chunk_data and be in numpy arrays\n",
    "#     :param input_length: amount of lagged values that I want to use with each timestep\n",
    "#     :param output_length:\n",
    "#     :param only_window: controller on the type of output. If true is is univariate. If false still\n",
    "#     univariate but now also forecasts a series of timesteps\n",
    "#     :return: the x_train an y_train, info and forecast for the lstm\n",
    "#     \"\"\"\n",
    "#     # put data back into continuous matrix\n",
    "#     data = data.reshape((data.shape[0] * data.shape[1], data.shape[2]))\n",
    "#     x_train = []\n",
    "#     y_train = []\n",
    "#     start_point = 0  # start gathering training data at the beginning\n",
    "#\n",
    "#     # move over data one time step at a time\n",
    "#     for _ in range(len(data)):\n",
    "#         input_data_end = start_point + input_length\n",
    "#         # output will currently cover timestep forecasts t+1 to t+20\n",
    "#         output_data_end = input_data_end + output_length\n",
    "#\n",
    "#         if output_data_end <= len(data):\n",
    "#             x_train.append(data[start_point:input_data_end, 0:-1])\n",
    "#             if only_window:\n",
    "#                 # arrays are set to get the info into [samples, timestep, feature]\n",
    "#                 y_train.append([[data[input_data_end, -1]]])\n",
    "#             else:\n",
    "#                 y_train.append(data[input_data_end:output_data_end, forecast_column_index])\n",
    "#\n",
    "#         start_point += 1  # move ahead one time step\n",
    "#\n",
    "#     return array(x_train), array(y_train)\n",
    "\n",
    "def normalize_data(df):\n",
    "    \"\"\"\n",
    "    Normalizes the data to number between [-1, 1] inclusive.\n",
    "\n",
    "    :param df: data to normalize\n",
    "    :return: the newly scaled data\n",
    "    \"\"\"\n",
    "    x_train = df.values\n",
    "    scaler = MinMaxScaler()\n",
    "    x_scaled = scaler.fit_transform(x_train)\n",
    "    return pd.DataFrame(x_scaled, columns=df.columns)\n",
    "\n",
    "\n",
    "# def chunk_data(data, chunk_size):  # older version\n",
    "#     \"\"\"\n",
    "#     function chunks the data into several equally sized data chunks, all of them meant to\n",
    "#     be inputted into the LSTM as such. This is a point to messing around to test performance\n",
    "#     to see if smaller or larger chunk sizes get better performance.\n",
    "#\n",
    "#     :param data: data input, mean to be numpy array from dataFrame.values\n",
    "#     :param chunk_size: number of samples to take from the data given\n",
    "#     :return: chunked data\n",
    "#     \"\"\"\n",
    "#     balancer = data.shape[0] % chunk_size\n",
    "#     if balancer == 0:\n",
    "#         return array(split(data, len(data)/chunk_size))\n",
    "#     else:\n",
    "#         # needed since all arrays must be balanced for number of features\n",
    "#         # This removes the extra features that would result in an uneven balance on the last array\n",
    "#         # only removes the final elements\n",
    "#         removal_list = []\n",
    "#         for i in range(balancer, 0, -1):\n",
    "#             removal_list.append(data.shape[0] - i)\n",
    "#\n",
    "#         data = np.delete(data, removal_list, axis=0)\n",
    "#         return array(split(data, len(data) / chunk_size))\n",
    "\n",
    "def chunk_and_split_data_to_x_y_one_step_drop_off(df, chunk_size, expected_cols):\n",
    "    \"\"\"\n",
    "    Similar to chunk_and_split_data_to_x_y but instead of new data sections for each step. Each new\n",
    "    data matrix only moves one row ahead.\n",
    "\n",
    "    Takes in a dataframe whose data you want to use to train a model with. Removes the expected data output from the training dataset.\n",
    "    Sets up the expected data in the correct format and sets up the training data in the correct format\n",
    "    Mainly used to organize data for training with a neural network such as keras\n",
    "\n",
    "    :param df: A dataframe\n",
    "    :param chunk_size: The size of the 2D matrix that you want to use to train the model. Can handle any non-negative int lower in size than the input dataframe\n",
    "    :param expected_cols: The expected output columns that are the correct answer for the model. Aka your y\n",
    "    :return: training data and expected data\n",
    "    \"\"\"\n",
    "    balance_num = df.shape[0] % chunk_size\n",
    "    expected = df.loc[:, expected_cols]\n",
    "    expected = expected[chunk_size + balance_num:].values  # drops the balance value and drops the first chunk size number of values\n",
    "    expected = expected.reshape(expected.shape[0], 1)\n",
    "    df = df.drop(columns=expected_cols)\n",
    "    if balance_num == 0:\n",
    "        training_data = df.values\n",
    "        data_out = []\n",
    "        for i in range(training_data.shape[0] - chunk_size):  # drops the last chunk size of values. Since otherwise we would be operating out of the data range.\n",
    "            data_out.append(training_data[i:i + chunk_size])\n",
    "    else:\n",
    "        df = df.drop(df.index[range(balance_num)])\n",
    "        training_data = df.values\n",
    "        data_out = []\n",
    "        for i in range(training_data.shape[0] - chunk_size):  # drops the last chunk size of values. Since otherwise we would be operating out of the data range.\n",
    "            data_out.append(training_data[i:i + chunk_size])\n",
    "\n",
    "    df = df.drop(df.index[range(chunk_size + balance_num)])\n",
    "\n",
    "    return np.array(data_out), expected, df\n",
    "\n",
    "\n",
    "def chunk_and_split_data_to_x_y(df, chunk_size, expected_cols):\n",
    "    \"\"\"\n",
    "    Built to replace both chunk_data and split_data_to_x_y. Does the exact same job but now with a lot less steps.\n",
    "\n",
    "    Built to separate out chunks of data. Each data chunk will be of dataframe columns and chunk_sze 2D matrix. The row values will not\n",
    "    repeat. So each data chunk contains new values. If you want repeating one step moving 2D matrixes use chunk_and_split_data_to_x_y_one_step_drop_off\n",
    "\n",
    "    Takes in a dataframe whose data you want to use to train a model with. Removes the expected data output from the training dataset.\n",
    "    Sets up the expected data in the correct format and sets up the training data in the correct format\n",
    "    Mainly used to organize data for training with a neural network such as keras\n",
    "\n",
    "    :param df: A dataframe\n",
    "    :param chunk_size: The size of the 2D matrix that you want to use to train the model. Can handle any non-negative int lower in size than the input dataframe\n",
    "    :param expected_cols: The expected output columns that are the correct answer for the model. Aka your y\n",
    "    :return: training data and expected data\n",
    "    \"\"\"\n",
    "    balance_num = df.shape[0] % chunk_size\n",
    "    expected = df.loc[:, expected_cols]\n",
    "    expected = expected[chunk_size + balance_num:].values\n",
    "    expected_out = []\n",
    "    for i in range(0, expected.shape[0], chunk_size):\n",
    "        expected_out.append(i)\n",
    "    expected_out = np.array(expected_out)\n",
    "    expected_out = expected_out.reshape(expected_out.shape[0], 1)\n",
    "\n",
    "    df = df.drop(columns=expected_cols)\n",
    "    df = df.drop(df.index[range((chunk_size * -1), 0)])  # drops the last chunk size of values. Since otherwise we would be operating out of the data range.\n",
    "    if balance_num == 0:\n",
    "        training_data = df.values\n",
    "        training_data = np.array(np.split(training_data, len(training_data)/chunk_size))\n",
    "    else:\n",
    "        df = df.drop(df.index[range(balance_num)])\n",
    "        training_data = df.values\n",
    "        training_data = np.array(np.split(training_data, len(training_data)/chunk_size))\n",
    "\n",
    "    return training_data, expected_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Small example of using the above code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                           altimeter_set_1 wind_cardinal_direction_set_1d  \\\ndate_time                                                                   \n2005-01-01 00:10:00+00:00         78191.09                             SW   \n2005-01-01 00:20:00+00:00         78191.09                            SSW   \n2005-01-01 00:55:00+00:00         78191.09                             SW   \n2005-01-01 01:45:00+00:00         78191.09                            SSW   \n2005-01-01 01:55:00+00:00         78191.09                             SW   \n...                                    ...                            ...   \n2010-12-31 19:57:00+00:00         77694.89                            WSW   \n2010-12-31 20:57:00+00:00         77694.89                             NW   \n2010-12-31 21:57:00+00:00         77747.12                              N   \n2010-12-31 22:57:00+00:00         77799.35                              0   \n2010-12-31 23:57:00+00:00         77877.70                            WNW   \n\n                           wind_gust_set_1  cloud_layer_2_code_set_1  \\\ndate_time                                                              \n2005-01-01 00:10:00+00:00            11.32                     212.0   \n2005-01-01 00:20:00+00:00            11.32                     223.0   \n2005-01-01 00:55:00+00:00            10.29                     853.0   \n2005-01-01 01:45:00+00:00            10.29                     203.0   \n2005-01-01 01:55:00+00:00            11.32                     222.0   \n...                                    ...                       ...   \n2010-12-31 19:57:00+00:00             0.00                       0.0   \n2010-12-31 20:57:00+00:00             0.00                       0.0   \n2010-12-31 21:57:00+00:00             7.20                       0.0   \n2010-12-31 22:57:00+00:00             0.00                       0.0   \n2010-12-31 23:57:00+00:00             0.00                       0.0   \n\n                           cloud_layer_3_code_set_1  wind_chill_set_1d  \\\ndate_time                                                                \n2005-01-01 00:10:00+00:00                       0.0              -3.99   \n2005-01-01 00:20:00+00:00                       0.0              -3.81   \n2005-01-01 00:55:00+00:00                       0.0              -3.81   \n2005-01-01 01:45:00+00:00                     803.0              -3.62   \n2005-01-01 01:55:00+00:00                       0.0              -3.62   \n...                                             ...                ...   \n2010-12-31 19:57:00+00:00                       0.0               0.00   \n2010-12-31 20:57:00+00:00                       0.0             -15.33   \n2010-12-31 21:57:00+00:00                       0.0             -12.95   \n2010-12-31 22:57:00+00:00                       0.0               0.00   \n2010-12-31 23:57:00+00:00                       0.0               0.00   \n\n                          weather_summary_set_1d  heat_index_set_1d  \\\ndate_time                                                             \n2005-01-01 00:10:00+00:00              scattered                0.0   \n2005-01-01 00:20:00+00:00                 broken                0.0   \n2005-01-01 00:55:00+00:00                 broken                0.0   \n2005-01-01 01:45:00+00:00                 broken                0.0   \n2005-01-01 01:55:00+00:00              scattered                0.0   \n...                                          ...                ...   \n2010-12-31 19:57:00+00:00                  clear                0.0   \n2010-12-31 20:57:00+00:00                  clear                0.0   \n2010-12-31 21:57:00+00:00                  clear                0.0   \n2010-12-31 22:57:00+00:00                  clear                0.0   \n2010-12-31 23:57:00+00:00                  clear                0.0   \n\n                           sea_level_pressure_set_1  \\\ndate_time                                             \n2005-01-01 00:10:00+00:00                       0.0   \n2005-01-01 00:20:00+00:00                       0.0   \n2005-01-01 00:55:00+00:00                  101220.0   \n2005-01-01 01:45:00+00:00                       0.0   \n2005-01-01 01:55:00+00:00                  101180.0   \n...                                             ...   \n2010-12-31 19:57:00+00:00                  101290.0   \n2010-12-31 20:57:00+00:00                  101270.0   \n2010-12-31 21:57:00+00:00                  101300.0   \n2010-12-31 22:57:00+00:00                  101420.0   \n2010-12-31 23:57:00+00:00                  101560.0   \n\n                           sea_level_pressure_set_1d  ...  air_temp_set_1  \\\ndate_time                                             ...                   \n2005-01-01 00:10:00+00:00                   78112.91  ...             2.0   \n2005-01-01 00:20:00+00:00                   78112.91  ...             2.0   \n2005-01-01 00:55:00+00:00                   78134.39  ...             1.7   \n2005-01-01 01:45:00+00:00                   78112.91  ...             2.0   \n2005-01-01 01:55:00+00:00                   78112.91  ...             2.0   \n...                                              ...  ...             ...   \n2010-12-31 19:57:00+00:00                   78513.41  ...           -10.0   \n2010-12-31 20:57:00+00:00                   78427.57  ...            -8.9   \n2010-12-31 21:57:00+00:00                   78433.78  ...            -8.3   \n2010-12-31 22:57:00+00:00                   78533.03  ...            -8.9   \n2010-12-31 23:57:00+00:00                   78745.40  ...           -10.6   \n\n                           air_temp_high_6_hour_set_1  \\\ndate_time                                               \n2005-01-01 00:10:00+00:00                         0.0   \n2005-01-01 00:20:00+00:00                         0.0   \n2005-01-01 00:55:00+00:00                         0.0   \n2005-01-01 01:45:00+00:00                         0.0   \n2005-01-01 01:55:00+00:00                         0.0   \n...                                               ...   \n2010-12-31 19:57:00+00:00                         0.0   \n2010-12-31 20:57:00+00:00                         0.0   \n2010-12-31 21:57:00+00:00                         0.0   \n2010-12-31 22:57:00+00:00                         0.0   \n2010-12-31 23:57:00+00:00                        -8.3   \n\n                          dew_point_temperature_set_1d  ceiling_set_1  \\\ndate_time                                                               \n2005-01-01 00:10:00+00:00                        -1.05            0.0   \n2005-01-01 00:20:00+00:00                        -1.05            0.0   \n2005-01-01 00:55:00+00:00                        -1.14            0.0   \n2005-01-01 01:45:00+00:00                        -1.05            0.0   \n2005-01-01 01:55:00+00:00                        -1.05            0.0   \n...                                                ...            ...   \n2010-12-31 19:57:00+00:00                       -21.84            0.0   \n2010-12-31 20:57:00+00:00                       -20.74            0.0   \n2010-12-31 21:57:00+00:00                       -20.74            0.0   \n2010-12-31 22:57:00+00:00                       -21.84            0.0   \n2010-12-31 23:57:00+00:00                       -21.23            0.0   \n\n                           dew_point_temperature_set_1  \\\ndate_time                                                \n2005-01-01 00:10:00+00:00                          0.0   \n2005-01-01 00:20:00+00:00                          0.0   \n2005-01-01 00:55:00+00:00                          0.0   \n2005-01-01 01:45:00+00:00                          0.0   \n2005-01-01 01:55:00+00:00                          0.0   \n...                                                ...   \n2010-12-31 19:57:00+00:00                          0.0   \n2010-12-31 20:57:00+00:00                          0.0   \n2010-12-31 21:57:00+00:00                          0.0   \n2010-12-31 22:57:00+00:00                          0.0   \n2010-12-31 23:57:00+00:00                          0.0   \n\n                           air_temp_low_24_hour_set_1  \\\ndate_time                                               \n2005-01-01 00:10:00+00:00                         0.0   \n2005-01-01 00:20:00+00:00                         0.0   \n2005-01-01 00:55:00+00:00                         0.0   \n2005-01-01 01:45:00+00:00                         0.0   \n2005-01-01 01:55:00+00:00                         0.0   \n...                                               ...   \n2010-12-31 19:57:00+00:00                         0.0   \n2010-12-31 20:57:00+00:00                         0.0   \n2010-12-31 21:57:00+00:00                         0.0   \n2010-12-31 22:57:00+00:00                         0.0   \n2010-12-31 23:57:00+00:00                         0.0   \n\n                           precip_accum_six_hour_set_1  metar_origin_set_1  \\\ndate_time                                                                    \n2005-01-01 00:10:00+00:00                          0.0                 0.0   \n2005-01-01 00:20:00+00:00                          0.0                 0.0   \n2005-01-01 00:55:00+00:00                          0.0                 0.0   \n2005-01-01 01:45:00+00:00                          0.0                 0.0   \n2005-01-01 01:55:00+00:00                          0.0                 0.0   \n...                                                ...                 ...   \n2010-12-31 19:57:00+00:00                          0.0                 0.0   \n2010-12-31 20:57:00+00:00                          0.0                 0.0   \n2010-12-31 21:57:00+00:00                          0.0                 0.0   \n2010-12-31 22:57:00+00:00                          0.0                 0.0   \n2010-12-31 23:57:00+00:00                          0.0                 0.0   \n\n                           weather_cond_code_set_1  wind_direction_set_1  \ndate_time                                                                 \n2005-01-01 00:10:00+00:00                      0.0                 220.0  \n2005-01-01 00:20:00+00:00                      0.0                 210.0  \n2005-01-01 00:55:00+00:00                      0.0                 220.0  \n2005-01-01 01:45:00+00:00                      0.0                 210.0  \n2005-01-01 01:55:00+00:00                      0.0                 220.0  \n...                                            ...                   ...  \n2010-12-31 19:57:00+00:00                      0.0                 240.0  \n2010-12-31 20:57:00+00:00                      0.0                 310.0  \n2010-12-31 21:57:00+00:00                      0.0                 350.0  \n2010-12-31 22:57:00+00:00                      0.0                   0.0  \n2010-12-31 23:57:00+00:00                      0.0                 300.0  \n\n[62321 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>altimeter_set_1</th>\n      <th>wind_cardinal_direction_set_1d</th>\n      <th>wind_gust_set_1</th>\n      <th>cloud_layer_2_code_set_1</th>\n      <th>cloud_layer_3_code_set_1</th>\n      <th>wind_chill_set_1d</th>\n      <th>weather_summary_set_1d</th>\n      <th>heat_index_set_1d</th>\n      <th>sea_level_pressure_set_1</th>\n      <th>sea_level_pressure_set_1d</th>\n      <th>...</th>\n      <th>air_temp_set_1</th>\n      <th>air_temp_high_6_hour_set_1</th>\n      <th>dew_point_temperature_set_1d</th>\n      <th>ceiling_set_1</th>\n      <th>dew_point_temperature_set_1</th>\n      <th>air_temp_low_24_hour_set_1</th>\n      <th>precip_accum_six_hour_set_1</th>\n      <th>metar_origin_set_1</th>\n      <th>weather_cond_code_set_1</th>\n      <th>wind_direction_set_1</th>\n    </tr>\n    <tr>\n      <th>date_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2005-01-01 00:10:00+00:00</th>\n      <td>78191.09</td>\n      <td>SW</td>\n      <td>11.32</td>\n      <td>212.0</td>\n      <td>0.0</td>\n      <td>-3.99</td>\n      <td>scattered</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>78112.91</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>-1.05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>220.0</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:20:00+00:00</th>\n      <td>78191.09</td>\n      <td>SSW</td>\n      <td>11.32</td>\n      <td>223.0</td>\n      <td>0.0</td>\n      <td>-3.81</td>\n      <td>broken</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>78112.91</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>-1.05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>210.0</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 00:55:00+00:00</th>\n      <td>78191.09</td>\n      <td>SW</td>\n      <td>10.29</td>\n      <td>853.0</td>\n      <td>0.0</td>\n      <td>-3.81</td>\n      <td>broken</td>\n      <td>0.0</td>\n      <td>101220.0</td>\n      <td>78134.39</td>\n      <td>...</td>\n      <td>1.7</td>\n      <td>0.0</td>\n      <td>-1.14</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>220.0</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 01:45:00+00:00</th>\n      <td>78191.09</td>\n      <td>SSW</td>\n      <td>10.29</td>\n      <td>203.0</td>\n      <td>803.0</td>\n      <td>-3.62</td>\n      <td>broken</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>78112.91</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>-1.05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>210.0</td>\n    </tr>\n    <tr>\n      <th>2005-01-01 01:55:00+00:00</th>\n      <td>78191.09</td>\n      <td>SW</td>\n      <td>11.32</td>\n      <td>222.0</td>\n      <td>0.0</td>\n      <td>-3.62</td>\n      <td>scattered</td>\n      <td>0.0</td>\n      <td>101180.0</td>\n      <td>78112.91</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>-1.05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>220.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2010-12-31 19:57:00+00:00</th>\n      <td>77694.89</td>\n      <td>WSW</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>clear</td>\n      <td>0.0</td>\n      <td>101290.0</td>\n      <td>78513.41</td>\n      <td>...</td>\n      <td>-10.0</td>\n      <td>0.0</td>\n      <td>-21.84</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>240.0</td>\n    </tr>\n    <tr>\n      <th>2010-12-31 20:57:00+00:00</th>\n      <td>77694.89</td>\n      <td>NW</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-15.33</td>\n      <td>clear</td>\n      <td>0.0</td>\n      <td>101270.0</td>\n      <td>78427.57</td>\n      <td>...</td>\n      <td>-8.9</td>\n      <td>0.0</td>\n      <td>-20.74</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>310.0</td>\n    </tr>\n    <tr>\n      <th>2010-12-31 21:57:00+00:00</th>\n      <td>77747.12</td>\n      <td>N</td>\n      <td>7.20</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-12.95</td>\n      <td>clear</td>\n      <td>0.0</td>\n      <td>101300.0</td>\n      <td>78433.78</td>\n      <td>...</td>\n      <td>-8.3</td>\n      <td>0.0</td>\n      <td>-20.74</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>350.0</td>\n    </tr>\n    <tr>\n      <th>2010-12-31 22:57:00+00:00</th>\n      <td>77799.35</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>clear</td>\n      <td>0.0</td>\n      <td>101420.0</td>\n      <td>78533.03</td>\n      <td>...</td>\n      <td>-8.9</td>\n      <td>0.0</td>\n      <td>-21.84</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2010-12-31 23:57:00+00:00</th>\n      <td>77877.70</td>\n      <td>WNW</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>clear</td>\n      <td>0.0</td>\n      <td>101560.0</td>\n      <td>78745.40</td>\n      <td>...</td>\n      <td>-10.6</td>\n      <td>-8.3</td>\n      <td>-21.23</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>300.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>62321 rows Ã— 34 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/nelson/PycharmProjects/my_notes/Dummy_data_for_examples/flagstaff.csv\", index_col=\"date_time\", parse_dates=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first step that you need to do is shift the columns of the data that you are using to get the correct setup for forecasting.\n",
    "So in this case you want to forecast what the next visibility range is going to be in the timeseries.\n",
    "An easy example since this is just focused on showing what the code can do but the following steps will also work for n future time-steps along with\n",
    "forecasting whatever number of variable Dataframe columns that you want. Though keep in mind that forecasting is difficult so the more columns that you\n",
    "are forecasting and the father away the timestep the more likely the results will be terrible.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "time_step_shift = 1\n",
    "\n",
    "df[\"expected_visibility\"] = df[\"visibility_set_1\"].shift(time_step_shift)  # you will have to do this for every single column that you want to forecast\n",
    "df = df[time_step_shift:]  # drops all values where the expected columns are going to be nan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keep in mind that in the data above to actually use it for forecasting it would require you to convert the text data into strings and possible normalize some of the\n",
    "columns before feeding it to a neural network. As such it currently will not work."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_input_data, train_expected_data = chunk_and_split_data_to_x_y(df, chunk_size=20, expected_cols=\"expected_visibility\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[78191.09, 'SSW', 11.32, 223.0, 0.0, -3.81, 'broken', 0.0, 0.0,\n        78112.91, 80.49, 166.0, '0', 0.0, 0.0, 0.0, 0.0, 60339.29, 0.0,\n        10.0, 0.0, 8.23, 0.0, 0.0, 2.0, 0.0, -1.05, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 210.0],\n       [78191.09, 'SW', 10.29, 853.0, 0.0, -3.81, 'broken', 0.0,\n        101220.0, 78134.39, 81.63, 176.0, '0', 0.0, 0.0, 0.0, 0.0,\n        60339.29, 0.0, 10.0, 0.0, 7.2, 0.0, 0.0, 1.7, 0.0, -1.14, 0.0,\n        0.0, 0.0, 0.0, 0.0, 0.0, 220.0],\n       [78191.09, 'SSW', 10.29, 203.0, 803.0, -3.62, 'broken', 0.0, 0.0,\n        78112.91, 80.49, 152.0, '0', 0.0, 0.0, 0.0, 0.0, 60339.29, 0.0,\n        10.0, 0.0, 7.72, 0.0, 0.0, 2.0, 0.0, -1.05, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 210.0],\n       [78191.09, 'SW', 11.32, 222.0, 0.0, -3.62, 'scattered', 0.0,\n        101180.0, 78112.91, 80.49, 152.0, '0', 0.0, 0.0, 0.0, 0.0,\n        60339.29, 0.0, 10.0, 0.0, 7.72, 0.0, 0.0, 2.0, 0.0, -1.05, 0.0,\n        0.0, 0.0, 0.0, 0.0, 0.0, 220.0],\n       [78217.2, 'SW', 0.0, 193.0, 243.0, -3.99, 'broken', 0.0, 0.0,\n        78139.0, 80.49, 142.0, '0', 0.0, 0.0, 0.0, 0.0, 60359.44, 0.0,\n        10.0, 0.0, 8.75, 0.0, 0.0, 2.0, 0.0, -1.05, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 220.0],\n       [78217.2, 'SW', 0.0, 223.0, 0.0, -4.92, 'broken', 0.0, 101220.0,\n        78210.8, 86.48, 162.0, '0', 0.0, 0.0, 0.0, 0.0, 60359.44, 3004.0,\n        10.0, 0.0, 7.72, 0.0, 0.0, 1.0, 0.0, -1.03, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 230.0],\n       [78243.32, 'SW', 10.29, 242.0, 0.0, -5.11, 'scattered', 0.0, 0.0,\n        78236.99, 80.34, 162.0, '0', 0.0, 0.0, 0.0, 0.0, 60379.6, 0.0,\n        10.0, 0.0, 8.23, 0.0, 0.0, 1.0, 0.0, -2.05, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 230.0],\n       [78243.32, 'SW', 10.8, 492.0, 0.0, -5.11, 'scattered', 0.0,\n        101210.0, 78236.99, 80.34, 196.0, '0', 0.0, 0.0, 0.0, 0.0,\n        60379.6, 0.0, 10.0, 0.0, 8.23, 0.0, 0.0, 1.0, 0.0, -2.05, 0.0,\n        0.0, 0.0, 0.0, 0.0, 0.0, 220.0],\n       [78269.44, 'WSW', 0.0, 223.0, 283.0, -4.26, 'broken', 0.0, 0.0,\n        78263.11, 80.34, 156.0, '0', 0.0, 0.0, 0.0, 0.0, 60399.76, 0.0,\n        10.0, 0.0, 6.17, 0.0, 0.0, 1.0, 0.0, -2.05, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 240.0],\n       [78269.44, 'SW', 0.0, 223.0, 284.0, -4.71, 'overcast', 0.0,\n        101250.0, 78263.05, 86.48, 153.0, '0', 0.0, 0.0, 0.0, 0.0,\n        60399.76, 0.0, 10.0, 0.0, 7.2, 0.0, 0.0, 1.0, 0.0, -1.03, 0.0,\n        0.0, 0.0, 0.0, 0.0, 0.0, 220.0],\n       [78321.67, 'WSW', 0.0, 194.0, 0.0, -3.13, 'overcast', 0.0,\n        101310.0, 78315.33, 80.34, 106.0, '0', 0.6, 0.0, 0.0, 0.0,\n        60440.06, 3010.0, 10.0, 0.0, 4.12, 0.0, 0.0, 1.0, 2.2, -2.05,\n        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 240.0],\n       [78295.55, 'SW', 0.0, 174.0, 0.0, -4.7, 'overcast', 0.0, 0.0,\n        78361.66, 86.37, 123.0, '0', 0.0, 0.0, 0.0, 0.0, 60419.9, 0.0,\n        10.0, 0.0, 4.63, 0.0, 0.0, 0.0, 0.0, -2.03, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 230.0],\n       [78295.55, 'SW', 0.0, 143.0, 184.0, -4.37, 'overcast', 0.0, 0.0,\n        78361.66, 86.37, 83.0, '0', 0.0, 0.0, 0.0, 0.0, 60419.9, 0.0,\n        10.0, 0.0, 4.12, 0.0, 0.0, 0.0, 0.0, -2.03, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 230.0],\n       [78295.55, 'SW', 0.0, 0.0, 0.0, -5.0, 'overcast', 0.0, 101290.0,\n        78361.6, 92.96, 84.0, '0', 0.0, 2.8, 0.0, 0.0, 60419.9, 0.0,\n        10.0, 0.0, 5.14, 0.0, 0.0, 0.0, 0.0, -1.02, 0.0, 0.0, -1.7, 0.0,\n        0.0, 0.0, 230.0],\n       [78269.44, 'SSW', 0.0, 0.0, 0.0, -5.53, 'light snow', 0.0, 0.0,\n        78335.48, 92.96, 64.0, 'light snow', 0.0, 0.0, 0.0, 0.0,\n        60399.76, 0.0, 1.75, 0.0, 6.17, 0.0, 0.0, 0.0, 0.0, -1.02, 0.0,\n        0.0, 0.0, 0.0, 0.0, 20.0, 210.0],\n       [78269.44, 'SSW', 0.0, 94.0, 0.0, -5.0, 'light snow', 0.0, 0.0,\n        78335.48, 92.96, 63.0, 'light snow', 0.0, 0.0, 0.0, 0.0,\n        60399.76, 0.0, 3.0, 0.0, 5.14, 0.0, 0.0, 0.0, 0.0, -1.02, 0.0,\n        0.0, 0.0, 0.0, 0.0, 20.0, 210.0],\n       [78269.44, 'SW', 0.0, 0.0, 0.0, -5.28, 'overcast', 0.0, 101270.0,\n        78335.48, 92.96, 64.0, '0', 0.0, 0.0, 0.0, 0.0, 60399.76, 0.0,\n        10.0, 0.0, 5.66, 0.0, 0.0, 0.0, 0.0, -1.02, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 220.0],\n       [78295.55, 'WSW', 0.0, 0.0, 0.0, -3.58, 'light snow', 0.0, 0.0,\n        78361.6, 92.96, 64.0, 'light snow', 0.0, 0.0, 0.0, 0.0, 60419.9,\n        0.0, 2.5, 0.0, 3.09, 0.0, 0.0, 0.0, 0.0, -1.02, 0.0, 0.0, 0.0,\n        0.0, 0.0, 20.0, 240.0],\n       [78295.55, 'WSW', 0.0, 0.0, 0.0, -3.99, 'light snow', 0.0, 0.0,\n        78361.66, 86.37, 64.0, 'light snow', 0.0, 0.0, 0.0, 0.0, 60419.9,\n        0.0, 5.0, 0.0, 3.6, 0.0, 0.0, 0.0, 0.0, -2.03, 0.0, 0.0, 0.0,\n        0.0, 0.0, 20.0, 250.0],\n       [78295.55, 'WSW', 0.0, 0.0, 0.0, -3.09, 'overcast', 0.0, 101280.0,\n        78361.66, 86.37, 84.0, '0', 0.0, 0.0, 0.0, 0.0, 60419.9, 5002.0,\n        9.0, 0.0, 2.57, 0.0, 0.0, 0.0, 0.0, -2.03, 0.0, 0.0, 0.0, 0.0,\n        0.0, 0.0, 240.0]], dtype=object)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([9.])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_expected_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Final step to feed into network. Just giving the network the parameters that you will need to inform it as to what the input shapes are."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = train_input_data.shape[1], train_input_data.shape[2], train_expected_data.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}