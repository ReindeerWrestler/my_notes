{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Dispersion measures how spread out a set of data is. This is especially important in finance because one of the main ways risk is measured is in how spread out returns have been historically. If returns have been very tight around a central value, then we have less reason to worry. If returns have been all over the place, that is risky."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [ 4  9  9  9 11 28 30 31 35 35 37 37 40 53 62 73 74 91 94 95]\n",
      "Mean of X: 42.85\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(74)\n",
    "\n",
    "X = np.random.randint(100, size=20)\n",
    "\n",
    "# Sort them\n",
    "X = np.sort(X)\n",
    "print('X: %s' %(X))\n",
    "\n",
    "mu = np.mean(X)\n",
    "print('Mean of X:', mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Range is simply the difference between the maximum and minimum values in a dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of X: 91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Range of X: %s' %(np.ptp(X)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The mean absolute deviation is the average of the distances of observations from the arithmetic mean. We use the absolute value of the deviation, so that 5 above the mean and 5 below the mean both contribute 5, because otherwise the deviations always sum to 0."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute deviation of X: 24.204999999999995\n"
     ]
    }
   ],
   "source": [
    "abs_dispersion = [np.abs(mu - x) for x in X]\n",
    "MAD = np.sum(abs_dispersion)/len(abs_dispersion)\n",
    "print('Mean absolute deviation of X:', MAD)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Variance and standard deviation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of X: 834.5274999999999\n",
      "Standard deviation of X: 28.888189628289272\n"
     ]
    }
   ],
   "source": [
    "print('Variance of X:', np.var(X))\n",
    "print('Standard deviation of X:', np.std(X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One way to interpret standard deviation is by referring to Chebyshev's inequality. This tells us that the proportion of samples within $k$ standard deviations (that is, within a distance of $k \\\\cdot$ standard deviation) of the mean is at least $1 - 1/k^2$ for all $k>1$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations within 1.25 stds of mean: [9, 9, 9, 11, 28, 30, 31, 35, 35, 37, 37, 40, 53, 62, 73, 74]\n",
      "Confirming that 0.8 > 0.36\n"
     ]
    }
   ],
   "source": [
    "k = 1.25\n",
    "dist = k*np.std(X)\n",
    "l = [x for x in X if abs(x - mu) <= dist]\n",
    "print('Observations within', k, 'stds of mean:', l)\n",
    "print('Confirming that', float(len(l))/len(X), '>', 1 - 1/k**2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The bound given by Chebyshev's inequality seems fairly loose in this case. This bound is rarely strict, but it is useful because it holds for all data sets and distributions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Semivariance and semideviation\n",
    "Although variance and standard deviation tell us how volatile a quantity is, they do not differentiate between deviations upward and deviations downward. Often, such as in the case of returns on an asset, we are more worried about deviations downward. This is addressed by semivariance and semideviation, which only count the observations that fall below the mean. Semivariance is defined as\n",
    "\n",
    "$$ \\\\frac{\\\\sum_{X_i < \\\\mu} (X_i - \\\\mu)^2}{n_<} $$\n",
    "\n",
    "where $n_<$ is the number of observations which are smaller than the mean. Semideviation is the square root of the semivariance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semivariance of X: 514.3917307692309\n",
      "Semideviation of X: 22.680205703856192\n"
     ]
    }
   ],
   "source": [
    "lows = [e for e in X if e <= mu]\n",
    "\n",
    "semivar = np.sum( (lows - mu) ** 2 ) / len(lows)\n",
    "\n",
    "print('Semivariance of X:', semivar)\n",
    "print('Semideviation of X:', np.sqrt(semivar))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A related notion is target semivariance (and target semideviation), where we average the distance from a target of values which fall below that target:\n",
    "\n",
    "$$ \\\\frac{\\\\sum_{X_i < B} (X_i - B)^2}{n_{<B}} $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target semivariance of X: 117.8\n",
      "Target semideviation of X: 10.853570840972107\n"
     ]
    }
   ],
   "source": [
    "B = 19\n",
    "lows_B = [e for e in X if e <= B]\n",
    "semivar_B = sum(map(lambda x: (x - B)**2,lows_B))/len(lows_B)\n",
    "\n",
    "print('Target semivariance of X:', semivar_B)\n",
    "print('Target semideviation of X:', np.sqrt(semivar_B))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All of these computations will give you sample statistics, that is standard deviation of a sample of data. Whether or not this reflects the current true population standard deviation is not always obvious, and more effort has to be put into determining that. This is especially problematic in finance because all data are time series and the mean and variance may change over time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}