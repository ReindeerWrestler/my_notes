{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The standard error is a measure of the variance of the sample mean.\n",
    "\n",
    "Normally can only get a sample mean not a population mean.\n",
    "\n",
    "Confidence intervals informs the accuracy of the sample mean estimate\n",
    "\n",
    "Computing standard error assumes that the way that the sample was taken was unbiased, data is normal and independent.\n",
    "\n",
    "Normal 95% confidence interval to check mass of data sample means. checking to see if they are normal and fall within the expected range around the average\n",
    "\n",
    "Due to this don't report the sample mean as a single number is correct but that a range of +- error. Where the mean population has a 95% chance of lying on this range.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data\n",
    "# We'll set a seed here so our runs are consistent\n",
    "np.random.seed(10)\n",
    "\n",
    "# Let's define some 'true' population parameters, we'll pretend we don't know these.\n",
    "POPULATION_MU = 64\n",
    "POPULATION_SIGMA = 5\n",
    "\n",
    "# Generate our sample by drawing from the population distribution\n",
    "sample_size = 10\n",
    "heights = np.random.normal(POPULATION_MU, POPULATION_SIGMA, sample_size)\n",
    "mean_height = np.mean(heights)\n",
    "# calc standard error\n",
    "stats.sem(heights, ddof=0)\n",
    "# or\n",
    "SE = np.std(heights) / np.sqrt(sample_size)\n",
    "\n",
    "# calc intervals for t distrbution\n",
    "print('99% confidence interval:', stats.t.interval(0.99, df=9,\n",
    "                                                   loc=mean_height, scale=SE))\n",
    "print('95% confidence interval:', stats.t.interval(0.95, df = 9,\n",
    "                                                   loc=mean_height, scale=SE))\n",
    "print('80% confidence interval:', stats.t.interval(0.8, df = 9,\n",
    "                                                   loc=mean_height, scale=SE))\n",
    "\n",
    "# calc intervals for normal distrbution\n",
    "print('99% confidence interval:', stats.norm.interval(0.99, df=9,\n",
    "                                                   loc=mean_height, scale=SE))\n",
    "print('95% confidence interval:', stats.norm.interval(0.95, df = 9,\n",
    "                                                   loc=mean_height, scale=SE))\n",
    "print('80% confidence interval:', stats.norm.interval(0.8, df = 9,\n",
    "                                                   loc=mean_height, scale=SE))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examples of assumption violations\n",
    "\n",
    "Autocorrelated Data: This is because autocorrelated processes tend to produce more extreme values than normally distributed processes. This is due to new values being dependent on previous values, series that are already far from the mean are likely to stay far from the mean.\n",
    "\n",
    "Can be fooled if the process is still centered around a num\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
